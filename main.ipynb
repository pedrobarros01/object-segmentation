{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# Caminhos para imagens e máscaras\n",
    "IMAGE_DIR = 'database/VOC2012_train_val/VOC2012_train_val/JPEGImages/'\n",
    "MASK_DIR = 'database/VOC2012_train_val/VOC2012_train_val/SegmentationClass/'\n",
    "\n",
    "IMG_SIZE = (128, 128)  # Redimensionamento das imagens\n",
    "NUM_CLASSES = 21  # Pascal VOC tem 21 classes (20 + 1 fundo)\n",
    "\n",
    "def process_mask(mask):\n",
    "    \"\"\"Ajusta os valores da máscara para a faixa permitida e aplica one-hot encoding.\"\"\"\n",
    "    mask = np.clip(mask, 0, NUM_CLASSES - 1)  # Ajustar valores fora da faixa [0, 20]\n",
    "    mask = to_categorical(mask, num_classes=NUM_CLASSES)  # One-hot encoding\n",
    "    return mask\n",
    "\n",
    "def load_image_mask(image_path, mask_path):\n",
    "    \"\"\"Carrega uma imagem e sua máscara correspondente.\"\"\"\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)\n",
    "    mask = load_img(mask_path, target_size=IMG_SIZE, color_mode='grayscale')\n",
    "\n",
    "    # Converter para arrays NumPy\n",
    "    img = img_to_array(img) / 255.0  # Normalizar imagem para [0, 1]\n",
    "    mask = img_to_array(mask).astype(np.int32).squeeze()  # Remover dimensão extra\n",
    "\n",
    "    # Processar a máscara para garantir que esteja na faixa correta\n",
    "    mask = process_mask(mask)\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "def load_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Carrega todas as imagens e máscaras do diretório.\"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') and os.path.exists(os.path.join(image_dir, filename)) and os.path.exists(os.path.join(mask_dir, filename.replace('.jpg', '.png'))):\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            mask_path = os.path.join(mask_dir, filename.replace('.jpg', '.png'))\n",
    "\n",
    "            # Carregar imagem e máscara\n",
    "            img, mask = load_image_mask(img_path, mask_path)\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Carregar as imagens e máscaras\n",
    "X, Y = load_dataset(IMAGE_DIR, MASK_DIR)\n",
    "print(f\"Dataset carregado: {X.shape} imagens, {Y.shape} máscaras\")\n",
    "\n",
    "def plot_and_save(history, metric, save_path):\n",
    "    \"\"\"Gera e salva um gráfico da métrica fornecida.\"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    # Plotar os dados de treino e validação\n",
    "    plt.plot(history.history[metric], label=f'Train {metric}')\n",
    "    plt.plot(history.history[f'val_{metric}'], label=f'Val {metric}')\n",
    "    \n",
    "    plt.title(f'{metric.capitalize()} over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "    \n",
    "    # Salvar o gráfico\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()  # Fechar para liberar memória\n",
    "\n",
    "\n",
    "\n",
    "# Definir o modelo U-Net para segmentação semântica\n",
    "def unet_model(input_size=(128, 128, 3), num_classes=21):\n",
    "    inputs = tf.keras.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    bn = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = tf.keras.layers.UpSampling2D((2, 2))(bn)\n",
    "    d1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
    "\n",
    "    u2 = tf.keras.layers.UpSampling2D((2, 2))(d1)\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(u2)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Compilar o modelo\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento\n",
    "history = model.fit(X, Y, batch_size=8, epochs=25, validation_split=0.1)\n",
    "# Gerar e salvar os gráficos de Loss e Accuracy\n",
    "plot_and_save(history, 'loss', 'loss_plot.png')\n",
    "plot_and_save(history, 'accuracy', 'accuracy_plot.png')\n",
    "model.save('unet_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
