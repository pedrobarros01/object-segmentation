{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e-El00rNILM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "from sklearn.metrics import confusion_matrix, jaccard_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk70Gt3hNxkH"
      },
      "outputs": [],
      "source": [
        "def process_mask(mask):\n",
        "    mask = np.clip(mask, 0, NUM_CLASSES - 1)\n",
        "    mask = to_categorical(mask, num_classes=NUM_CLASSES)\n",
        "    return mask\n",
        "\n",
        "def load_image_mask(image_path, mask_path):\n",
        "    img = load_img(image_path, target_size=IMG_SIZE)\n",
        "    mask = load_img(mask_path, target_size=IMG_SIZE, color_mode='grayscale')\n",
        "    img = img_to_array(img) / 255.0\n",
        "    mask = img_to_array(mask).astype(np.int32).squeeze()\n",
        "    mask = process_mask(mask)\n",
        "    return img, mask\n",
        "\n",
        "def load_dataset(image_dir, mask_dir):\n",
        "    images = []\n",
        "    masks = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith('.jpg') and os.path.exists(os.path.join(mask_dir, filename.replace('.jpg', '.png'))):\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            mask_path = os.path.join(mask_dir, filename.replace('.jpg', '.png'))\n",
        "            img, mask = load_image_mask(img_path, mask_path)\n",
        "            images.append(img)\n",
        "            masks.append(mask)\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "def plot_and_save(history, metric, save_path):\n",
        "    plt.figure()\n",
        "    plt.plot(history.history[metric], label=f'Train {metric}')\n",
        "    plt.plot(history.history[f'val_{metric}'], label=f'Val {metric}')\n",
        "    plt.title(f'{metric.capitalize()} over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def unet_model(input_size=(128, 128, 3), num_classes=21):\n",
        "    inputs = tf.keras.Input(input_size)\n",
        "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "    bn = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    u1 = tf.keras.layers.UpSampling2D((2, 2))(bn)\n",
        "    d1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "    u2 = tf.keras.layers.UpSampling2D((2, 2))(d1)\n",
        "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(u2)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def data_generator(image_files, mask_files, batch_size, img_size=(128, 128), num_classes=21):\n",
        "    \"\"\"\n",
        "    Gera lotes de dados a partir de listas de caminhos de arquivos de imagem e máscara.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_img_files = image_files[i:i + batch_size]\n",
        "            batch_mask_files = mask_files[i:i + batch_size]\n",
        "            images, masks = [], []\n",
        "            for img_path, mask_path in zip(batch_img_files, batch_mask_files):\n",
        "                img = load_img(img_path, target_size=img_size)\n",
        "                mask = load_img(mask_path, target_size=img_size, color_mode='grayscale')\n",
        "                img = img_to_array(img) / 255.0\n",
        "                mask = img_to_array(mask).astype(np.int32).squeeze()\n",
        "                mask = np.clip(mask, 0, num_classes - 1)\n",
        "                mask = to_categorical(mask, num_classes=num_classes)  # Transformar em one-hot\n",
        "                images.append(img)\n",
        "                masks.append(mask)\n",
        "            yield np.array(images), np.array(masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PQeNQUSNONF"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"gopalbhattrai/pascal-voc-2012-dataset\")\n",
        "IMAGE_DIR = os.path.join(path, 'VOC2012_train_val/VOC2012_train_val/JPEGImages/')\n",
        "MASK_DIR = os.path.join(path, 'VOC2012_train_val/VOC2012_train_val/SegmentationClass/')\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "NUM_CLASSES = 21\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTYnYH4cYPvs"
      },
      "outputs": [],
      "source": [
        "image_files = []\n",
        "mask_files = []\n",
        "for filename in os.listdir(IMAGE_DIR):\n",
        "    if filename.endswith('.jpg') and os.path.exists(os.path.join(MASK_DIR, filename.replace('.jpg', '.png'))):\n",
        "        img_path = os.path.join(IMAGE_DIR, filename)\n",
        "        mask_path = os.path.join(MASK_DIR, filename.replace('.jpg', '.png'))\n",
        "        image_files.append(img_path)\n",
        "        mask_files.append(mask_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myEvtQoTKUFb"
      },
      "source": [
        "## Validação Cruzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vtpbeGQKe3M"
      },
      "source": [
        "A validação cruzada é uma técnica essencial para avaliar o desempenho de modelos de segmentação de imagens, ajudando a garantir que o modelo não esteja superajustado (overfitting) ao conjunto de dados de treinamento. Em vez de simplesmente treinar e testar o modelo uma única vez, a validação cruzada permite testar o modelo em diferentes subconjuntos de dados, proporcionando uma análise mais robusta e confiável de sua performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuHDtZDMKoUs"
      },
      "source": [
        "### K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ5EAjs8KsvM"
      },
      "source": [
        "O método mais comum, onde o conjunto de dados é dividido em \"K\" partes ou \"folds\".\n",
        "Processo:\n",
        "\n",
        "1. Dividir os dados em K partes de tamanho igual.\n",
        "2. Treinar o modelo em K-1 partes e testar na parte restante.\n",
        "3. Repetir o processo K vezes, alternando a parte de teste a cada repetição.\n",
        "4. Calcular a média das métricas de desempenho para obter uma avaliação geral do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZkseiEHxZw"
      },
      "source": [
        "# Métricas de Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ryh9OGH9yW"
      },
      "source": [
        "A avaliação de desempenho para esses modelos de segmentação é essencial para garantir que as previsões feitas sejam precisas e consistentes com as anotações manuais (ground truth). Sem uma avaliação adequada, é difícil medir melhorias, comparar diferentes abordagens ou ajustar modelos para aplicações reais. Ela também ajuda a detectar possíveis problemas como falsos positivos (quando o modelo identifica algo que não existe) e falsos negativos (quando o modelo deixa de identificar algo que está presente).\n",
        "\n",
        "Portanto, o processo de avaliação vai além de simplesmente observar as previsões visuais — envolve o uso de métricas quantitativas que ajudam a medir, comparar e melhorar a eficácia dos modelos de segmentação. Na próxima seção, exploraremos as métricas comuns usadas para essa análise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4drweKWQLW82"
      },
      "source": [
        "## Matriz de confusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuW2vF_FLjJo"
      },
      "source": [
        "A matriz de confusão é uma ferramenta fundamental para a avaliação de modelos de segmentação de imagens, permitindo uma análise detalhada de como o modelo está classificando cada classe de pixels. Ela mostra a distribuição de previsões corretas e incorretas feitas pelo modelo, o que facilita a identificação de padrões de erro específicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX24eHOUWTGa"
      },
      "outputs": [],
      "source": [
        "def compute_confusion_matrix(y_true, y_pred, num_classes=21):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    return confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VONTa_a9INuV"
      },
      "source": [
        " ## Métricas Comuns para Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJwuhFJhIQDM"
      },
      "source": [
        "### IoU (Intersection over Union)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM-eX6gfJS5i"
      },
      "source": [
        "Também conhecido como Jaccard Index, o IoU é uma das métricas mais populares para medir a precisão de segmentação. Ele calcula a sobreposição entre a área prevista pelo modelo e a área real (ground truth):\n",
        "\n",
        "$$\n",
        "IoU = \\frac{\\text{Área de interseção}}{\\text{Área de união}}\n",
        "$$\n",
        "\n",
        "\n",
        "Valores mais altos de IoU indicam uma melhor correspondência entre a segmentação prevista e a segmentação real. O IoU é utilizado para calcular o desempenho médio de um modelo em todas as classes (mIoU - Mean IoU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ikDa4j-WBmC"
      },
      "outputs": [],
      "source": [
        "def compute_iou(y_true, y_pred, num_classes=21):\n",
        "    ious = []\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        true_class = (y_true == cls)\n",
        "        pred_class = (y_pred == cls)\n",
        "\n",
        "        intersection = np.sum(true_class & pred_class)\n",
        "        union = np.sum(true_class | pred_class)\n",
        "\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))\n",
        "        else:\n",
        "            ious.append(intersection / union)\n",
        "\n",
        "    ious = [iou for iou in ious if not np.isnan(iou)]\n",
        "    return np.mean(ious)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA0LT21MMNux"
      },
      "source": [
        "### Mean IoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4zygl70ML3R"
      },
      "source": [
        "Mean Intersection over Union (Mean IoU) é uma média da métrica IoU calculada para cada classe. Ele mede a sobreposição entre a área prevista e a área real, considerando todas as classes e depois tirando a média.\n",
        "\n",
        "$$ \\text{IoU} = \\frac{\\text{Interseção}}{\\text{União}} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives} + \\text{False Negatives}} $$\n",
        "\n",
        "$$ \\text{mIoU} = \\frac{1}{C} \\sum_{i=1}^{C} \\text{IoU}_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fUn7OTpJYaf"
      },
      "source": [
        "### Accuracy (Precisão Geral)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMD5QbiXJbpr"
      },
      "source": [
        "Mede a proporção de pixels classificados corretamente pelo modelo em relação ao total de pixels.\n",
        "É uma métrica simples, mas pode ser enganosa em datasets desbalanceados, onde uma classe é dominante (ex.: segmentar uma imagem com muito céu e poucos objetos menores)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7QyyKG4JdOE"
      },
      "source": [
        "### Recall e Precision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuEF5pF8Jeqg"
      },
      "source": [
        "- **Recall (Sensibilidade):** Mede a capacidade do modelo de identificar todos os pixels de uma determinada classe. Um alto recall significa que poucos pixels reais foram deixados de fora.\n",
        "\n",
        "$$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} $$\n",
        "- **Precision (Precisão Específica):** Mede quantos dos pixels classificados como uma determinada classe são realmente dessa classe.\n",
        "\n",
        "$$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWdTME_8WQGy"
      },
      "outputs": [],
      "source": [
        "def compute_precision_recall(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    return precision, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIUY8mp0KBc5"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptqTktKrWLUu"
      },
      "source": [
        "$$ F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfHdMFWRWIQo"
      },
      "outputs": [],
      "source": [
        "def compute_f1_score(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    return f1_score(y_true, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWpgzMlWJlOP"
      },
      "source": [
        "### Curvas ROC e AUC (Area Under Curve)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB2VPOS1Jn19"
      },
      "source": [
        "- Embora mais comuns em problemas de classificação binária, as curvas ROC (Receiver Operating Characteristic) também podem ser usadas para segmentação, ajudando a entender a sensibilidade do modelo a diferentes limiares de decisão.\n",
        "\n",
        "- AUC (Área Sob a Curva) fornece uma medida da capacidade geral de separação do modelo. Valores próximos a 1 indicam bom desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XKiqoa7bbAD"
      },
      "outputs": [],
      "source": [
        "def plot_roc_auc(y_true, y_pred, num_classes):\n",
        "    \"\"\"\n",
        "    Plota a curva ROC e calcula a AUC média para cada classe.\n",
        "    \"\"\"\n",
        "    y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
        "    y_pred_bin = label_binarize(y_pred, classes=np.arange(num_classes))\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(num_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Calcular AUC média\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    mean_tpr /= num_classes\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(all_fpr, mean_tpr, color='blue', label=f'Mean ROC (AUC = {np.mean(list(roc_auc.values())):.2f})', lw=2)\n",
        "    plt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Mean ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return np.mean(list(roc_auc.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqEapn_3eYf9"
      },
      "outputs": [],
      "source": [
        "def plot_combined_roc_auc(y_true, y_pred, num_classes):\n",
        "    \"\"\"\n",
        "    Plota a curva ROC e calcula a AUC para dados agregados de todas as dobras.\n",
        "    \"\"\"\n",
        "    y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
        "    y_pred_bin = label_binarize(y_pred, classes=np.arange(num_classes))\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(num_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Calcular AUC média\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    mean_tpr /= num_classes\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(all_fpr, mean_tpr, color='blue', label=f'Mean ROC (AUC = {np.mean(list(roc_auc.values())):.2f})', lw=2)\n",
        "    plt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Combined ROC Curve Across Folds')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return np.mean(list(roc_auc.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKqPDNe3LlHt"
      },
      "source": [
        "## Métricas Específicas para Segmentação Semântica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJXybJ4KLu8a"
      },
      "source": [
        "### Boundary F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j5WdGo2Lyi9"
      },
      "source": [
        "O Boundary F1 Score mede a precisão das bordas ou contornos dos objetos segmentados. Ele é útil em aplicações onde a precisão dos contornos é crítica, como em análise médica (por exemplo, segmentação de tumores) ou visão industrial (como identificar bordas de peças).\n",
        "\n",
        "$$ \\text{Boundary Precision} = \\frac{\\text{Bordas Verdadeiras Positivas}}{\\text{Bordas Verdadeiras Positivas} + \\text{Bordas Falsas Positivas}}$$\n",
        "\n",
        "$$ \\text{Boundary Recall} = \\frac{\\text{Bordas Verdadeiras Positivas}}{\\text{Bordas Verdadeiras Positivas} + \\text{Bordas Falsas Negativas}}$$\n",
        "\n",
        "$$\\text{Boundary F1} = 2 \\times \\frac{\\text{Boundary Precision} \\times \\text{Boundary Recall}}{\\text{Boundary Precision} + \\text{Boundary Recall}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu3tUCqKbYBI"
      },
      "outputs": [],
      "source": [
        "def compute_boundary_f1(y_true, y_pred, dilation_radius=1):\n",
        "    \"\"\"\n",
        "    Calcula o Boundary F1 Score. Dilata as bordas para calcular interseções.\n",
        "    \"\"\"\n",
        "    from skimage.morphology import dilation, square\n",
        "    y_true_boundary = dilation(y_true, square(dilation_radius)) - y_true\n",
        "    y_pred_boundary = dilation(y_pred, square(dilation_radius)) - y_pred\n",
        "\n",
        "    true_positives = np.sum(y_true_boundary & y_pred_boundary)\n",
        "    false_positives = np.sum(~y_true_boundary & y_pred_boundary)\n",
        "    false_negatives = np.sum(y_true_boundary & ~y_pred_boundary)\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives + 1e-7)\n",
        "    recall = true_positives / (true_positives + false_negatives + 1e-7)\n",
        "\n",
        "    boundary_f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
        "    return boundary_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBl7kZ2zLyp5"
      },
      "source": [
        "### Pixel Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WORX9vWOMbcV"
      },
      "source": [
        "Pixel Accuracy mede a proporção de pixels que foram corretamente classificados pelo modelo em relação ao total de pixels na imagem.\n",
        "\n",
        "$$ \\text{Pixel Accuracy} = \\frac{\\text{Número de Pixels Corretos}}{\\text{Número Total de Pixels}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmRypfWNbBo3"
      },
      "outputs": [],
      "source": [
        "def compute_pixel_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula a precisão de pixels.\n",
        "    \"\"\"\n",
        "    correct_pixels = np.sum(y_true == y_pred)\n",
        "    total_pixels = len(y_true)\n",
        "    return correct_pixels / total_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG-Qjm6IYs5W"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "__4OiAlbYDQe",
        "outputId": "a5dccb1c-9e90-4ab0-afc7-cb538e28fdb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treinando na dobra 1/5...\n",
            "Epoch 1/25\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 2s/step - accuracy: 0.6770 - loss: 0.8773\n",
            "Epoch 2/25\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 2s/step - accuracy: 0.7113 - loss: 0.6536\n",
            "Epoch 3/25\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 2s/step - accuracy: 0.7142 - loss: 0.6504\n",
            "Epoch 4/25\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 2s/step - accuracy: 0.7198 - loss: 0.6399\n",
            "Epoch 5/25\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 2s/step - accuracy: 0.7254 - loss: 0.6288\n",
            "Epoch 6/25\n",
            "\u001b[1m 89/291\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 2s/step - accuracy: 0.7325 - loss: 0.6245"
          ]
        }
      ],
      "source": [
        "model_save_dir = './trained_models'\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "# Inicializar listas para armazenar métricas\n",
        "iou_scores = []\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "pixel_accuracy_scores = []\n",
        "boundary_f1_scores = []\n",
        "auc_scores = []\n",
        "conf_matrices = []\n",
        "\n",
        "# Validação cruzada K-Fold\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "fold = 1\n",
        "for train_index, test_index in kf.split(image_files):\n",
        "    print(f\"Treinando na dobra {fold}/{k}...\")\n",
        "\n",
        "    # Separar caminhos das imagens de treino e teste\n",
        "    train_img_files = [image_files[i] for i in train_index]\n",
        "    train_mask_files = [mask_files[i] for i in train_index]\n",
        "\n",
        "    # Criar geradores para treino\n",
        "    train_gen = data_generator(train_img_files, train_mask_files, BATCH_SIZE)\n",
        "\n",
        "    # Definir o número de passos por época para treino\n",
        "    steps_per_epoch = len(train_img_files) // BATCH_SIZE\n",
        "\n",
        "    # Criar o modelo\n",
        "    model = unet_model()\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Treinar o modelo usando geradores\n",
        "    model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "    # Salvar o modelo desta dobra\n",
        "    model.save(os.path.join(model_save_dir, f'unet_model_fold_{fold}.h5'))\n",
        "    print(f\"Modelo da dobra {fold} salvo.\")\n",
        "\n",
        "    fold += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWEwnYuyfuQ9"
      },
      "outputs": [],
      "source": [
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "fold = 1\n",
        "for train_index, test_index in kf.split(image_files):\n",
        "    print(f\"Avaliando o modelo da dobra {fold}/{k}...\")\n",
        "\n",
        "    # Carregar o modelo salvo\n",
        "    model_path = os.path.join(model_save_dir, f'unet_model_fold_{fold}.h5')\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Separar caminhos das imagens de teste\n",
        "    test_img_files = [image_files[i] for i in test_index]\n",
        "    test_mask_files = [mask_files[i] for i in test_index]\n",
        "\n",
        "    # Criar gerador para validação\n",
        "    test_gen = data_generator(test_img_files, test_mask_files, BATCH_SIZE)\n",
        "    validation_steps = len(test_img_files) // BATCH_SIZE\n",
        "\n",
        "    # Fazer previsões e calcular métricas\n",
        "    y_true, y_pred = [], []\n",
        "    for i in range(validation_steps):\n",
        "        imgs, masks = next(test_gen)\n",
        "        preds = model.predict(imgs)\n",
        "        y_pred_classes = np.argmax(preds, axis=-1)\n",
        "        y_true_classes = np.argmax(masks, axis=-1)\n",
        "        y_true.extend(y_true_classes.flatten())\n",
        "        y_pred.extend(y_pred_classes.flatten())\n",
        "\n",
        "    # Armazenar dados para curva ROC e matriz de confusão combinada\n",
        "    all_y_true.extend(y_true)\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "    # Calcular e armazenar métricas\n",
        "    iou = compute_iou(np.array(y_true), np.array(y_pred), NUM_CLASSES)\n",
        "    f1 = compute_f1_score(np.array(y_true), np.array(y_pred))\n",
        "    precision, recall = compute_precision_recall(np.array(y_true), np.array(y_pred))\n",
        "    pixel_acc = compute_pixel_accuracy(np.array(y_true), np.array(y_pred))\n",
        "    boundary_f1 = compute_boundary_f1(np.array(y_true), np.array(y_pred))\n",
        "    auc_score = plot_roc_auc(np.array(y_true), np.array(y_pred), NUM_CLASSES)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(NUM_CLASSES))\n",
        "\n",
        "    # Guardar valores\n",
        "    iou_scores.append(iou)\n",
        "    f1_scores.append(f1)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    pixel_accuracy_scores.append(pixel_acc)\n",
        "    boundary_f1_scores.append(boundary_f1)\n",
        "    auc_scores.append(auc_score)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "    print(f\"Dobra {fold} - Resultados:\")\n",
        "    print(f\"IoU Médio: {iou}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"Pixel Accuracy: {pixel_acc}\")\n",
        "    print(f\"Boundary F1 Score: {boundary_f1}\")\n",
        "    print(f\"AUC Média: {auc_score}\")\n",
        "\n",
        "    fold += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOJWz-2GekRh"
      },
      "outputs": [],
      "source": [
        "combined_auc = plot_combined_roc_auc(np.array(all_y_true), np.array(all_y_pred), NUM_CLASSES)\n",
        "print(f\"\\nAUC Média Combinada de Todas as Dobras: {combined_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfXH9GAHelvZ"
      },
      "outputs": [],
      "source": [
        "# Calcular matriz de confusão combinada\n",
        "combined_conf_matrix = confusion_matrix(all_y_true, all_y_pred, labels=np.arange(NUM_CLASSES))\n",
        "print(\"\\nMatriz de Confusão Combinada:\")\n",
        "print(combined_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJWpq9P0Z6k1"
      },
      "outputs": [],
      "source": [
        "mean_iou = np.mean(iou_scores)\n",
        "std_iou = np.std(iou_scores)\n",
        "\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "\n",
        "mean_pixel_accuracy = np.mean(pixel_accuracy_scores)\n",
        "std_pixel_accuracy = np.std(pixel_accuracy_scores)\n",
        "\n",
        "mean_boundary_f1 = np.mean(boundary_f1_scores)\n",
        "std_boundary_f1 = np.std(boundary_f1_scores)\n",
        "\n",
        "mean_auc = np.mean(auc_scores)\n",
        "std_auc = np.std(auc_scores)\n",
        "\n",
        "print(\"\\nResultados Médios após Validação Cruzada (Média ± Desvio Padrão):\")\n",
        "print(f\"Média IoU: {mean_iou:.4f} ± {std_iou:.4f}\")\n",
        "print(f\"Média F1-Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "print(f\"Média Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Média Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
        "print(f\"Média Pixel Accuracy: {mean_pixel_accuracy:.4f} ± {std_pixel_accuracy:.4f}\")\n",
        "print(f\"Média Boundary F1 Score: {mean_boundary_f1:.4f} ± {std_boundary_f1:.4f}\")\n",
        "print(f\"Média AUC: {mean_auc:.4f} ± {std_auc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "myEvtQoTKUFb",
        "8mZkseiEHxZw",
        "4drweKWQLW82",
        "oJwuhFJhIQDM",
        "tA0LT21MMNux",
        "1fUn7OTpJYaf",
        "H7QyyKG4JdOE",
        "VIUY8mp0KBc5",
        "FKqPDNe3LlHt",
        "iJXybJ4KLu8a",
        "OBl7kZ2zLyp5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}